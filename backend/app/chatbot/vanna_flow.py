import os
import time
import json
import re
import pandas as pd
import traceback
from sqlalchemy import create_engine
from sqlalchemy import text
from enum import Enum
from typing import List, Optional, Dict, Any
from dataclasses import dataclass, field

# from vanna.remote import VannaDefault
from app.chatbot.vanna_client import MyVanna

from .config import (
    DB_HOST,
    DB_PORT,
    DB_USER,
    DB_PASSWORD,
    DB_NAME
)

from .ollama_llm import OllamaLlm

from .prompt import (
    get_additional_sql_prompt,
    get_additional_summary_prompt,
    get_question_classifier_prompt,
)

########################################
# 1. Kiá»ƒu tráº¡ng thÃ¡i / phÃ¢n loáº¡i cÃ¢u há»i
########################################

class ResponseStatus(Enum):
    SUCCESS = True
    WARNING = True
    ERROR   = False

class QuestionType(str, Enum):
    SQL_REQUIRED   = "SQL_REQUIRED"    # cáº§n truy váº¥n DB
    DOCUMENTATION  = "DOCUMENTATION"   # tra cá»©u tÃ i liá»‡u / chÃ­nh sÃ¡ch
    GENERAL        = "GENERAL"         # cÃ¢u há»i chung chung

########################################
# 2. Cáº¥u trÃºc káº¿t quáº£ tráº£ vá» cho frontend
########################################

@dataclass
class QuestionResponse:
    status: ResponseStatus
    question: str
    question_type: Optional[QuestionType] = None
    answer: Optional[str] = None
    sql: Optional[str] = None
    error_message: Optional[str] = None
    execution_time: Optional[float] = None
    rows_count: Optional[int] = None
    related_docs: Optional[List] = None
    images: Optional[List[str]] = None


_ollama_llm: OllamaLlm | None = None


def get_ollama_llm() -> OllamaLlm:
    global _ollama_llm
    if _ollama_llm is None:
        _ollama_llm = OllamaLlm()
    return _ollama_llm

########################################
# 3. Flow xá»­ lÃ½ cÃ¢u há»i
########################################

import logging

logger = logging.getLogger(__name__)

SQL_HINT_PATTERNS = [
    r"\btop\s*\d+\b",
    r"bÃ¡n\s+cháº¡y",
    r"doanh\s*thu",
    r"Ä‘Æ¡n\s*hÃ ng",
    r"tá»“n\s*kho",
    r"thá»‘ng\s*kÃª",
    r"bÃ¡o\s*cÃ¡o",
    r"bao\s*nhiÃªu",
    r"tá»•ng\s+sá»‘",
    r"theo\s+(ngÃ y|thÃ¡ng|nÄƒm)",
    r"lá»£i\s*nhuáº­n",
    r"sáº£n\s*pháº©m",
    r"khÃ¡ch\s*hÃ ng",
]

def heuristic_question_type(question: str) -> Optional[QuestionType]:
    q = (question or "").lower().strip()
    for pat in SQL_HINT_PATTERNS:
        if re.search(pat, q):
            return QuestionType.SQL_REQUIRED
    return None

class VannaChatFlow:
    def __init__(self, vn: MyVanna):
        self.question_classifier_prompt = get_question_classifier_prompt()
        self.additional_summary_prompt = get_additional_summary_prompt()
        self.additional_sql_prompt = get_additional_sql_prompt()

        # âœ… Engine local Ä‘á»ƒ Ä‘á»c schema + execute SQL
        self.engine = create_engine(
            f"mysql+pymysql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}?charset=utf8mb4",
            pool_pre_ping=True,
        )

        self.vn = vn

    # 4.1 PhÃ¢n loáº¡i cÃ¢u há»i
    def classify_question(self, question: str) -> "QuestionType":
        """
        PhÃ¢n loáº¡i cÃ¢u há»i báº±ng Ollama:
        - SQL_REQUIRED
        - DOCUMENTATION
        - GENERAL
        """
        # âœ… 0. Heuristic override (nhanh â€“ ráº» â€“ chÃ­nh xÃ¡c)
        hinted = heuristic_question_type(question)
        if hinted is not None:
            print(f"[classify_question][heuristic] '{question}' -> {hinted}")
            return hinted

        llm = get_ollama_llm()
        system_prompt = get_question_classifier_prompt()

        label = llm.classify_question(system_prompt=system_prompt, question=question)

        if label == "SQL_REQUIRED":
            qt = QuestionType.SQL_REQUIRED
        elif label == "DOCUMENTATION":
            qt = QuestionType.DOCUMENTATION
        else:
            qt = QuestionType.GENERAL

        print(f"[classify_question] '{question}' -> {qt}")
        return qt
    
     # 4.2b Tráº£ lá»i cÃ¢u há»i GENERAL (small talk, chÃ o há»i...)
    def answer_general(self, question: str, **kwargs) -> str:
        """
        Tráº£ lá»i cÃ¡c cÃ¢u há»i GENERAL (chÃ o há»i, small talk) báº±ng LLM,
        KHÃ”NG tra cá»©u tÃ i liá»‡u, KHÃ”NG sinh SQL.
        """
        try:
            system_prompt = """
            Báº¡n lÃ  má»™t trá»£ lÃ½ AI thÃ¢n thiá»‡n cá»§a cá»­a hÃ ng.

            Nhiá»‡m vá»¥:
            - TrÃ² chuyá»‡n, chÃ o há»i ngÆ°á»i dÃ¹ng.
            - HÆ°á»›ng dáº«n ngÆ°á»i dÃ¹ng cÃ¡ch Ä‘áº·t cÃ¢u há»i vá»:
            + bÃ¡o cÃ¡o doanh sá»‘ / Ä‘Æ¡n hÃ ng / sáº£n pháº©m
            + chÃ­nh sÃ¡ch bÃ¡n hÃ ng, Ä‘á»•i tráº£, thanh toÃ¡n, Ä‘Äƒng kÃ½, Ä‘Äƒng nháº­p,...

            QUY Táº®C:
            - Tráº£ lá»i 100% báº±ng tiáº¿ng Viá»‡t.
            - Ngáº¯n gá»n, tá»± nhiÃªn, lá»‹ch sá»±.
            - XÆ°ng "mÃ¬nh" hoáº·c "tÃ´i", gá»i ngÆ°á»i dÃ¹ng lÃ  "báº¡n".
            - Náº¿u ngÆ°á»i dÃ¹ng chá»‰ chÃ o (vÃ­ dá»¥: "xin chÃ o", "hello", "hi"):
            â†’ tráº£ lá»i má»™t cÃ¢u chÃ o thÃ¢n thiá»‡n vÃ  gá»£i Ã½ há» há»i tiáº¿p.
            """.strip()

            # Gá»™p thÃ nh 1 prompt ngáº¯n gá»n Ä‘á»ƒ tá»‘i Æ°u tá»‘c Ä‘á»™
            prompt = f"{system_prompt}\n\nNgÆ°á»i dÃ¹ng: {question}\nTrá»£ lÃ½:"

            # TÃ¹y báº¡n Ä‘áº·t tÃªn hÃ m Ollama client, vÃ­ dá»¥ ask_llm/generate/chat...
            # á»ž Ä‘Ã¢y giáº£ Ä‘á»‹nh báº¡n cÃ³ self.ollama.generate(text, max_tokens=..., temperature=...)
            llm = get_ollama_llm()
            return llm.reply_general(
                system_prompt=system_prompt,
                question=question,
            )
        
        except Exception as e:
            print(f"âŒ Tráº£ lá»i GENERAL tháº¥t báº¡i: {e}")
            # fallback an toÃ n náº¿u LLM bá»‹ lá»—i
            return "ChÃ o báº¡n! Hiá»‡n mÃ¬nh Ä‘ang gáº·p má»™t chÃºt sá»± cá»‘, báº¡n thá»­ há»i láº¡i sau Ã­t phÃºt nhÃ©."

    # 4.2b Flow tráº£ lá»i DOCUMENTATION
    def answer_from_docs(self, question: str, **kwargs) -> tuple[str, List]:
        """
        Tráº£ lá»i cÃ¢u há»i báº±ng cÃ¡ch sá»­ dá»¥ng tÃ i liá»‡u ná»™i bá»™
        """
        try:
            # B1: Láº¥y tÃ i liá»‡u liÃªn quan
            print("ðŸ“š Äang tra cá»©u tÃ i liá»‡u liÃªn quan...")
            raw_docs = self.get_related_documentation(question)
            if not raw_docs:
                return (
                    "Xin lá»—i, tÃ´i khÃ´ng tÃ¬m tháº¥y tÃ i liá»‡u liÃªn quan Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i cá»§a báº¡n.",
                    [],
                )
            # B2: Chuáº©n hÃ³a tÃ i liá»‡u
            doc_context = "\n\n".join(
                [f"Document {i+1}: {doc}" for i, doc in enumerate(raw_docs)]
            )
            # B3: Sinh cÃ¢u tráº£ lá»i tá»« tÃ i liá»‡u
            print("ðŸ’­ Äang sinh cÃ¢u tráº£ lá»i tá»« tÃ i liá»‡u...")
            llm = get_ollama_llm()

            system_prompt = """
            Báº¡n lÃ  trá»£ lÃ½ AI cá»§a cá»­a hÃ ng. Tráº£ lá»i 100% báº±ng tiáº¿ng Viá»‡t.
            Chá»‰ sá»­ dá»¥ng thÃ´ng tin trong tÃ i liá»‡u Ä‘Æ°á»£c cung cáº¥p. Náº¿u tÃ i liá»‡u khÃ´ng Ä‘á»§, nÃ³i rÃµ lÃ  chÆ°a cÃ³ thÃ´ng tin.
            Ngáº¯n gá»n, Ä‘Ãºng trá»ng tÃ¢m.
            """.strip()

            # raw_docs lÃ  list string/tÃ i liá»‡u báº¡n Ä‘Ã£ láº¥y Ä‘Æ°á»£c
            docs_json = json.dumps([{"doc": d} for d in raw_docs], ensure_ascii=False)

            answer = llm.summarize_answer(
                system_prompt=system_prompt,
                question=question,
                data_json=docs_json,
                extra_instructions="ÄÃ¢y lÃ  cÃ¢u há»i DOCUMENTATION. Chá»‰ dá»±a trÃªn ná»™i dung tÃ i liá»‡u trong JSON Ä‘á»ƒ tráº£ lá»i.",
            )
            return answer, raw_docs

        except Exception as e:
            print(f"âŒ Táº¡o cÃ¢u tráº£ lá»i tá»« tÃ i liá»‡u khÃ´ng thÃ nh cÃ´ng: {e}")
            return (
                f"Xin lá»—i, Ä‘Ã£ cÃ³ lá»—i xáº£y ra khi truy xuáº¥t thÃ´ng tin tá»« tÃ i liá»‡u: {str(e)}",
                [],
            )
        
    def _schema_text(self) -> str:
        return """
    Tables:
    - products(id, name, price, category_id)
    - orders(id, customer_id, created_at)
    - order_items(order_id, product_id, quantity, price)
    - categories(id, name)
    """



    def _generate_sql(self, question: str, **kwargs) -> str:
        try:
            # Láº¥y schema tinh gá»n Ä‘á»ƒ náº¡p vÃ o prompt (trÃ¡nh quÃ¡ táº£i token)
            schema_hint = self._build_schema_hint(question) 
            
            prompt = f"""
            Báº¡n lÃ  chuyÃªn gia MySQL 8.0. 
            Schema: {schema_hint}
            Nhiá»‡m vá»¥: Chuyá»ƒn cÃ¢u há»i sau thÃ nh SQL.
            Quy táº¯c: 
            - CHá»ˆ tráº£ vá» cÃ¢u lá»‡nh SQL SELECT.
            - KHÃ”NG giáº£i thÃ­ch, KHÃ”NG dÃ¹ng markdown.
            CÃ¢u há»i: {question}
            SQL:"""

            # Gá»i Model (2) chuyÃªn sinh SQL
            llm = get_ollama_llm()
            # Sá»­ dá»¥ng hÃ m chat thÃ´ng thÆ°á»ng thay vÃ¬ vn.generate_sql náº¿u muá»‘n kiá»ƒm soÃ¡t hoÃ n toÃ n prompt
            raw_sql = llm._chat(
                model=llm.config.general_model, 
                messages=[{"role": "user", "content": prompt}],
                num_predict=llm.config.max_tokens_general,
            )
            
            return self._cleanup_sql(raw_sql)
        except Exception as e:
            print("--- DEBUG TRACEBACK ---")
            traceback.print_exc() # DÃ²ng nÃ y sáº½ in ra chÃ­nh xÃ¡c lá»—i náº±m á»Ÿ file nÃ o, dÃ²ng nÃ o
            raise e
    
    _schema_hint_cache: Optional[str] = None

    def _pick_tables_for_question(self, question: str, all_tables: list[str]) -> list[str]:
        q = (question or "").lower()
        # Heuristic tá»‘i thiá»ƒu cho bÃ i toÃ¡n bÃ¡n hÃ ng
        preferred = []
        if "sáº£n pháº©m" in q or "bÃ¡n cháº¡y" in q or "top" in q:
            for name in ["products", "product", "order_items", "orders", "order", "categories", "brands"]:
                for t in all_tables:
                    if t.lower() == name:
                        preferred.append(t)
        # fallback: láº¥y tá»‘i Ä‘a 10 báº£ng Ä‘áº§u náº¿u khÃ´ng match
        if not preferred:
            preferred = all_tables[:10]
        # loáº¡i trÃ¹ng
        seen = set()
        out = []
        for t in preferred:
            if t not in seen:
                seen.add(t)
                out.append(t)
        return out[:10]

    def _build_schema_hint(self, question: str) -> str:
        hint_lines = []
        with self.engine.connect() as conn:
            rows = conn.execute(text("SHOW TABLES")).fetchall()
            all_tables = [r[0] for r in rows]
            picked = self._pick_tables_for_question(question, all_tables)

            for t in picked:
                cols = conn.execute(text(f"SHOW COLUMNS FROM `{t}`")).fetchall()
                col_desc = ", ".join([f"{c[0]} {c[1]}" for c in cols])
                hint_lines.append(f"- {t}({col_desc})")

        # Giá»›i háº¡n Ä‘á»™ dÃ i Ä‘á»ƒ agent á»•n Ä‘á»‹nh
        schema_hint = "\n".join(hint_lines)
        return schema_hint[:6000]

    def validate_sql(self, sql: str) -> bool:
        """Validate SQL cÃ³ an toÃ n Ä‘á»ƒ execute khÃ´ng"""
        low = sql.strip().lower()
        dangerous = ["update ", "delete ", "insert ", "drop ", "alter ", "truncate "]
        if not low.startswith("select"):
            return False
        return not any(k in low for k in dangerous)
        # return self.vn.is_sql_valid(sql)
    
    def _cleanup_sql(self, sql: str) -> str:
        """
        LÃ m sáº¡ch output tá»« LLM Ä‘á»ƒ láº¥y Ä‘Ãºng 1 cÃ¢u SELECT ... MySQL.
        - BÃ³c bá» ``` ```sql
        - Bá» tiá»n tá»‘ 'SQL:' náº¿u cÃ³
        - Láº¥y tá»« dÃ²ng báº¯t Ä‘áº§u báº±ng SELECT trá»Ÿ Ä‘i
        - Bá» dáº¥u ; cuá»‘i cÃ¹ng náº¿u cÃ³
        """
        if not isinstance(sql, str):
            return ""

        # 1. Loáº¡i bá» mÃ£ markdown ```sql ... ```
        sql = re.sub(r"^```sql\s*", "", sql.strip(), flags=re.IGNORECASE)
        sql = re.sub(r"^```\s*", "", sql.strip(), flags=re.IGNORECASE)
        sql = re.sub(r"\s*```$", "", sql.strip(), flags=re.IGNORECASE)

        # 2. Loáº¡i bá» kÃ½ tá»± xuá»‘ng dÃ²ng thá»«a, khoáº£ng tráº¯ng thá»«a
        sql = sql.strip()

        # 3. XÃ³a nhá»¯ng dÃ²ng rá»—ng Ä‘áº§u/cuá»‘i
        lines = [line.strip() for line in sql.splitlines() if line.strip()]
        sql = " ".join(lines)

        # 4. Äáº£m báº£o cÃ¢u lá»‡nh báº¯t Ä‘áº§u báº±ng SELECT
        if not sql.lower().startswith("select"):
            raise Exception(f"Model tráº£ vá» khÃ´ng pháº£i cÃ¢u SELECT há»£p lá»‡: {sql}")

        # 5. XÃ³a dáº¥u ; thá»«a (náº¿u báº¡n muá»‘n)
        if sql.endswith(";"):
            sql = sql[:-1].strip()

        return sql
    
    def run_sql(self, sql: str) -> pd.DataFrame:
        engine = create_engine(
            f"mysql+pymysql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}?charset=utf8mb4"
        )
        return pd.read_sql(sql, engine)

    # 4.5 Thá»±c thi SQL vÃ  chuáº©n bá»‹ data
    def execute_sql_safe(self, sql: str) -> pd.DataFrame:
        """
        Thá»±c thi SQL vÃ  tráº£ vá» DataFrame.
        - Chá»‰ cháº¡y SQL qua Vanna (MySQL connector mÃ  Vanna Ä‘ang giá»¯).
        - CÃ³ kiá»ƒm tra an toÃ n SQL trÆ°á»›c khi cháº¡y.
        - QuÄƒng lá»—i rÃµ rÃ ng.
        """

        try:
            clean_sql = sql.strip().rstrip(";")

            if not self.validate_sql(clean_sql):
                raise Exception("CÃ¢u lá»‡nh SQL bá»‹ cháº·n vÃ¬ khÃ´ng an toÃ n.")

            # Vanna: vn.run_sql -> tráº£ vá» pandas.DataFrame
            df = self.run_sql(clean_sql)
            print("[DEBUG DF]\n", df.head(), "\n", df.dtypes)
            
            if df is None:
                raise Exception("Query tráº£ vá» None thay vÃ¬ DataFrame.")

            if not isinstance(df, pd.DataFrame):
                raise Exception(f"Query khÃ´ng tráº£ vá» DataFrame: {type(df)}")

            return df

        except Exception as e:
            raise Exception(f"Thá»±c thi SQL tháº¥t báº¡i: {str(e)}")

    # 4.6 TÃ³m táº¯t káº¿t quáº£ DataFrame báº±ng tiáº¿ng Viá»‡t
    def generate_answer(self, question: str, df: pd.DataFrame) -> str:
        """
        TÃ³m táº¯t káº¿t quáº£ truy váº¥n SQL báº±ng Ollama LLM.
        Chá»‰ gá»­i má»™t lÆ°á»£ng dá»¯ liá»‡u JSON vá»«a pháº£i lÃªn model.
        """
        llm = get_ollama_llm()
        system_prompt = get_additional_summary_prompt()

        # # Náº¿u khÃ´ng cÃ³ dá»¯ liá»‡u
        # if df is None or df.empty:
        #     data_json = "[]"
        # else:
        #     # Giáº£m sá»‘ dÃ²ng gá»­i lÃªn Ä‘á»ƒ trÃ¡nh prompt quÃ¡ dÃ i, vÃ­ dá»¥ max 50 dÃ²ng
        #     df_to_send = df.head(10)
        #     data_json = df_to_send.to_json(orient="records", force_ascii=False)

        # answer = llm.summarize_answer(
        #     system_prompt=system_prompt,
        #     question=question,
        #     data_json=data_json,
        # )
        # 1. Gá»t giÅ©a dá»¯ liá»‡u (Chá»‰ láº¥y cá»™t cáº§n thiáº¿t Ä‘á»ƒ tiáº¿t kiá»‡m token)
        # Loáº¡i bá» cÃ¡c cá»™t rÃ¡c Ä‘Ã£ nÃ³i á»Ÿ bÆ°á»›c trÆ°á»›c
        blacklist = ['description', 'image_url', 'created_at', 'brand_id']
        clean_df = df.drop(columns=[c for c in blacklist if c in df.columns]).head(5)
        
        data_json = clean_df.to_json(orient='records', force_ascii=False)

        # 2. Táº¡o ná»™i dung yÃªu cáº§u (User Prompt) rÃµ rÃ ng
        user_content = f"""
    HÃ£y tráº£ lá»i cÃ¢u há»i sau dá»±a trÃªn dá»¯ liá»‡u thá»±c táº¿.

    CÃ‚U Há»ŽI: {question}
    Dá»® LIá»†U JSON Tá»ª Há»† THá»NG: {data_json}

    TRáº¢ Lá»œI:"""

        # 3. Gá»i model tÃ³m táº¯t
        return llm._chat(
            model=llm.config.summary_model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_content}
            ],
            num_predict=200 # Giá»›i háº¡n Ä‘á»™ dÃ i Ä‘á»ƒ trÃ¡nh model láº£m nháº£m
        )
        return answer

    # 4.7 Flow tá»•ng há»£p: nháº­n cÃ¢u há»i tá»« user vÃ  tráº£ vá» QuestionResponse
    def ask_question(
        self,
        question: str,
        allow_llm_to_see_data: bool = True,
        **kwargs,
    ) -> QuestionResponse:
        """
        Enhanced function Ä‘á»ƒ xá»­ lÃ½ cÃ¢u há»i vá»›i preprocessing Ä‘á»ƒ phÃ¢n biá»‡t SQL vs Documentation

        Args:
            question: CÃ¢u há»i cá»§a user
            allow_llm_to_see_data: Cho phÃ©p LLM xem data Ä‘á»ƒ tá»‘i Æ°u SQL
            retry_config: Cáº¥u hÃ¬nh retry logic

        Returns:
            QuestionResponse object chá»©a answer vÃ  metadata
        """

        t0 = time.time()
        logger.info(f"[ASK] Nháº­n cÃ¢u há»i: {question}")

        response = QuestionResponse(status=ResponseStatus.SUCCESS, question=question)

        try:
            # --- (1) PHÃ‚N LOáº I (DÃ¹ng model nhá») ---
            t1 = time.time()
            question_type = self.classify_question(question)
            t2 = time.time()
            logger.info(f"[ASK] classify_question máº¥t {t2 - t1:.2f}s, loáº¡i={question_type}")

            response.question_type = question_type
            print(f"ðŸ“ Loáº¡i cÃ¢u há»i: {question_type.value}")

            # 1. GENERAL => LLM tráº£ lá»i trá»±c tiáº¿p (khÃ´ng dÃ¹ng tÃ i liá»‡u, khÃ´ng SQL)
            if question_type == QuestionType.GENERAL:
                print("ðŸ’¬ Xá»­ lÃ½ cÃ¢u há»i GENERAL (small talk)...")
                answer = self.answer_general(question, **kwargs)
                response.answer = answer
                # response.execution_time = time.time() - start_time
                # print(
                #     f"âœ… ÄÃ£ tráº£ lá»i GENERAL trong {response.execution_time:.2f}s"
                # )
                return response

            # 2. DOCUMENTATION => tra cá»©u tÃ i liá»‡u ná»™i bá»™ (RAG)
            if question_type == QuestionType.DOCUMENTATION:
                print("ðŸ“š Xá»­ lÃ½ cÃ¢u há»i DOCUMENTATION (tra cá»©u tÃ i liá»‡u)...")
                answer, related_docs = self.answer_from_docs(
                    question, **kwargs
                )
                response.answer = answer
                response.related_docs = related_docs
                # response.execution_time = time.time() - start_time
                # print(
                #     f"âœ… ÄÃ£ tra cá»©u tÃ i liá»‡u trong {response.execution_time:.2f}s"
                # )
                return response
        
            # 3.SQL_REQUIRED => CÃ¢u há»i cáº§n SQL â†’ sinh SQL + thá»±c thi
            t3 = time.time()
            sql = None
            df = None

            sql = self._generate_sql(question, **kwargs)
            response.sql = sql

            t4 = time.time()
            logger.info(f"[ASK] generate_sql máº¥t {t4 - t3:.2f}s, sql={sql}")

            # Thá»±c thi SQL an toÃ n
            df = self.execute_sql_safe(sql)
            response.rows_count = len(df)

            t5 = time.time()
            logger.info(f"[ASK] run_sql máº¥t {t5 - t4:.2f}s, rows={len(df) if df is not None else 0}")

            # KhÃ´ng cÃ³ SQL há»£p lá»‡
            if not sql or sql.strip() == "":
                response.status = ResponseStatus.WARNING
                response.error_message = (
                    "KhÃ´ng thá»ƒ táº¡o SQL tá»« cÃ¢u há»i"
                )
                response.answer = "KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u phÃ¹ há»£p cho cÃ¢u há»i cá»§a báº¡n."
                return response

            # Thá»±c thi SQL nhÆ°ng khÃ´ng cÃ³ dá»¯ liá»‡u
            if df is None or df.empty:
                response.status = ResponseStatus.WARNING
                response.error_message = "Truy váº¥n Ä‘Æ°á»£c thá»±c hiá»‡n nhÆ°ng khÃ´ng cÃ³ dá»¯ liá»‡u tráº£ vá»"
                response.answer = "KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u phÃ¹ há»£p cho cÃ¢u há»i cá»§a báº¡n."
                return response

            # Dá»¯ liá»‡u quÃ¡ nhiá»u báº£n ghi â†’ cáº£nh bÃ¡o + tÃ³m táº¯t top 50
            if len(df) > 50:
                response.status = ResponseStatus.WARNING
                response.error_message = "Truy váº¥n Ä‘Æ°á»£c thá»±c hiá»‡n nhÆ°ng tráº£ vá» quÃ¡ nhiá»u dÃ²ng"
                response.answer = "CÃ¢u há»i quÃ¡ rá»™ng, báº¡n hÃ£y Ä‘áº·t cÃ¢u há»i cá»¥ thá»ƒ hÆ¡n Ä‘á»ƒ cÃ³ káº¿t quáº£ tá»‘t nháº¥t."
                return response

            # # TÃ¡ch image khá»i df náº¿u cÃ³
            # df, images = split_base64_from_df(df)
            # print(f"ðŸ–¼ï¸ Got {len(images)} images")
            # response.images = images
            # response.rows_count = len(df)

            # # Format Ä‘á»‹nh dáº¡ng tiá»n VNÄ => giÃºp LLM dá»… hiá»ƒu hÆ¡n
            # df = format_dataframe(df)

            # BÃ¬nh thÆ°á»ng: sinh cÃ¢u tráº£ lá»i tá»« toÃ n bá»™ DataFrame
            t6 = time.time()
            answer = self.generate_answer(question, df, **kwargs)
            response.answer = answer

            t7 = time.time()
            logger.info(f"[ASK] summarize_answer máº¥t {t7 - t6:.2f}s")
            logger.info(f"[ASK] Tá»•ng thá»i gian request: {t7 - t0:.2f}s")

            response.execution_time = t7 - t0
            print(f"âœ… QuÃ¡ trÃ¬nh xá»­ lÃ½ SQL hoÃ n táº¥t trong {response.execution_time:.2f}s")
            # # Tá»•ng thá»i gian cháº¡y
            # response.execution_time = time.time() - start_time
            # print(f"âœ… QuÃ¡ trÃ¬nh xá»­ lÃ½ SQL hoÃ n táº¥t trong {response.execution_time:.2f}s")

        except Exception as e:
            # Báº¯t má»i lá»—i vÃ  tráº£ vá» cho frontend
            response.status = ResponseStatus.ERROR
            response.error_message = str(e)
            response.answer = "KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u phÃ¹ há»£p cho cÃ¢u há»i cá»§a báº¡n."
            response.execution_time = time.time() - t0
            # response.execution_time = time.time() - start_time
            print(f"âŒ Error: {e}")

        return response

########################################
# 4. HÃ m khá»Ÿi táº¡o / retrain cho app.main dÃ¹ng
########################################

# giá»¯ 1 biáº¿n toÃ n cá»¥c
_vanna_flow: VannaChatFlow | None = None

def initialize_flow(qa_seed_path: str = "seed/qa_seed.json"):
    """
    Gá»i hÃ m nÃ y khi server start hoáº·c khi admin nháº¥n `Retrain`.
    - Táº¡o MyVanna (káº¿t ná»‘i LM Studio + Chroma)
    - Train schema (DDL)
    - Train Q&A máº«u
    - Táº¡o flow
    """

    # Train data chá»‰ 1 láº§n khi khá»Ÿi táº¡o
    # # Train schema
    # vn.train_schema(TABLES)

    # # Train Q&A seed
    # if qa_seed_path and os.path.exists(qa_seed_path):
    #     try:
    #         with open(qa_seed_path, "r", encoding="utf-8") as f:
    #             qa_pairs = json.load(f)
    #     except Exception as e:
    #         print("[initialize_flow] Lá»—i Ä‘á»c qa_seed.json:", e)
    #         qa_pairs = []
    #     vn.train_qa_pairs(qa_pairs)


    global _vanna_flow
    if _vanna_flow is None:
        vn = MyVanna()
        _vanna_flow = VannaChatFlow(vn=vn)

def get_vanna_flow() -> VannaChatFlow:
    if _vanna_flow is None:
        initialize_flow()
    return _vanna_flow